---
title: "Predicción oleaje"
subtitle: "20582- Análisis de Datos para el GMAT"
date: today
author: Melcion Ciudad Bosch
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
output:
  html_document:
    citation_package: natbib
  df_print: paged
bibliography: bibbliografia.bib
csl: apa.csl
Rendering:
    embed-resources: true
---

Podemos encontrar todo el código en el [repositorio](https://github.com/mcbosch/Prediccion-oleaje/tree/main) de GitHub

```{r, include=FALSE, echo=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(ggplot2)
library(ggcorrplot)
library(MASS)
library(jpeg)
library(Hotelling)
library(patchwork)
```

# Introducción

La predicción de la situación costera es muy importante para logística portuaria, para la pesca, para la seguridad de zonas costeras y para cualquier aficionado al deporte. El ayuntamiento de Bilbao dispone de una boya para medir la altura de una ola y su periodo. en la playa de Arrietaram una playa muy concurrida por los surfistas. Además disponen de un anómetro costero para medir también el viento. Entonces quieremos proporcionar una predicción del oleaje y la calidad de la ola para hacer surf, asi ayudamos a los  y las surfistas que frecuentan estas playas.

Sin embargo no puedemos medir la energía de las olas. Entonces han alquilado una boya a la empresa datawell para que tambien les mida la energía de las olas durante 100 días, una vez por la mañana con marea alta y otra por la tarde con marea baja.

<div style="text-align: center;">
  <img src="playa.jpg" alt="Arrietaram" width="250px"  >
</div>

Para proporcionar una web de predicción del oleaje modelizaremos la energía de las ola con los datos que puede proporcionar su boya. Además definiremos una variable que nos diga la calidad de la ola y miraremos si podemos relacionarla también con los datos que tenemos.

Las muestras de datos són aleatorias generadas a partir de funciones de R. Para aportar realismo hemos hecho una interpretación de datos que hemos obtenido de aplicaciones como WindGuru, Windy o TodoSurf (que solo son semanales). Además para la generación de datos definimos una dependencia temporal, ya que no seria lógico que hoy hubiese olas de dos metros y a las 12 horas el mar este en calma.

Planteamos la hipotesis de que un viento de tierra viene relacionado con una disminución de la energía y la altura, pero un aumento del periodo. Y que para un viento de mar provoca el efecto contrario. Para hacer este contraste realizaremos un contraste de medias restringiendo nuestros datos a los dos tipos de viento. Además veremos que la temperatura del agua no influye en las características de la ola.


```{r, echo=FALSE, message=FALSE}
covarianza <- matrix(c(13, 77, -2, 0.25,
                       77, 5000, 134, 10,
                       -2, 134, 6, 0.12,
                       0.25, 10, 0.12, 0.05), ncol = 4, byrow = TRUE)

medias <- c(8, 164, 10, 1.3)

set.seed(43)
datos_numericos <- mvrnorm(200, mu = medias, covarianza) %>% as.tibble()
names(datos_numericos) <- c('V','En','P','A')

# Limitamos a resultados realistas

datos_numericos <- datos_numericos %>%
  mutate(
    V = pmax(V, 0),    
    En = pmin(pmax(En, 1), 5000),  # Energía entre 1 y 5000
    P = pmin(pmax(P, 5), 20),      # Periodo entre 5 y 20 s
    A = pmin(pmax(A, 0), 20)      # Altura entre 0 y 20 m
  )
# Suponemos que nuestra bolla mide cada 12 horas
direccion_viento <- sample(c('N','W','S','E',
                             'NW','NE','SW','SE'),200, replace = TRUE)
marea <- rep(c("ALTA", "BAJA"), times = 100)

primer_dia <- as.Date("2017-01-01") 
fechas <- seq(from = primer_dia, by ='day', length.out = 100) 
DAT = c()
for (i in 1:100){
  DAT = c(DAT, paste(as.character(fechas[i]), 'mañana'),paste(as.character(fechas[i]), 'tarde'))
}
datos_cual <- tibble(DV = direccion_viento,
                    M  = marea,
                    DAT = DAT)

# Añadimos una dependencia temporal
for (i in 2:200) {
  datos_numericos$A[i] <- 0.3 * datos_numericos$A[i - 1] + 
    0.5 * datos_numericos$A[i] + (datos_numericos$V[i]/8*1.3)*0.2 
  
  datos_numericos$En[i] <- 0.3 * datos_numericos$En[i - 1] + 
    0.7 * datos_numericos$En[i]
}



datos <- tibble(datos_numericos,datos_cual)

kaggle_data <- read.csv('kaggle_data.csv',header = TRUE) 
datos_nuevos <- kaggle_data  %>%  
  filter(grepl('8:00',Date.Time) | grepl('20:00',Date.Time)) %>%
  dplyr::select(Date.Time,SST) %>% slice(1:200)


fechas <- seq(from = primer_dia, by ='day', length.out = 100) 
DATK = c()
for (i in 1:100){
  DATK = c(DATK, paste(as.character(fechas[i]), 'mañana'),paste(as.character(fechas[i]), 'tarde'))
}

datos_nuevos <- datos_nuevos %>% mutate(
  Date.Time = DATK) 
names(datos_nuevos) <- c('DAT','SST')

datos <- datos %>% right_join(datos_nuevos) 
```

Añadiremos la variable SST que indica la temperatura de la superficie del agua de la base de datos de [@author2023web]. Para los contrastes de hipótesis hemos utilizado los apuntes de [@apuntes]

# Analisis exploratorio:

Observemos nuestros datos. En el estudio de () salió que el termostato de la bolla fallo algunos dias, lo podemos observar en la siguiente tabla. Entonces deberemos filtrar estos datos

```{r, echo=FALSE}
glimpse(datos %>% arrange(SST))
```
Observamos que trabajamos con 8 variables, en el siguiente oren:

-   *Viento* en nudos
-   *Energía* en kJ
-   *Periodo* em segundos
-   *Altura* de la ola en metros
-   *Dirección viento* que puede tomar los valores: Norte (N), Este(E), Oeste(W), Sud(S), Nor-este(NE), Nor-oeste(NW), sureste(SE) y suroeste (SW)
-   *Marea* que puede ser alta o baja (en nuestro experimento hacemos una medición con la marea alta y otra con la marea baja, que serian cada 12 horas)
-   *Fecha* que es el dia y hora de la medición 
-   *SST*, Surface Sea Temperature, una variable de la base de datos [esta]()


Para hacer un estudio de nuestras variables primero reoordenaremos nuestros datos y filtremos en los que fallo el termostato:
```{r, }
datos <- datos[,c('DAT','V','En','P','SST','A','DV','M')]
datos <- datos %>% filter(SST > 0)
datos_numericos <- datos %>% dplyr::select(V,En,P,SST,A)

```

Calculemos la varianza generalizada y la varianza total. Estos dos datos nos dice la dispersión de nuestras observaciones y 

```{r, echo=FALSE}
S <- cov(datos_numericos)
print(paste('Varianza total: ', as.character(det(S))))
print(paste('Varianza generalizada: ',as.character(sum(diag(S)))))
```
Pues observamos que obtenemos datos bastante dispersos sin embargo al mirar la matriz vemos que la variable que aporta toda esta dispersión es en mayor proporción la energía, de hecho observemos estos valores cuando no tenemos en cuenta la energia:

```{r, echo=FALSE}
S2 <- datos_numericos %>% dplyr::select(V,P,SST,A) %>% cov()
print(paste('Varianza total: ', as.character(det(S2))))
print(paste('Varianza generalizada: ',as.character(sum(diag(S2)))))
```
Hacemos un analisis de las relaciones de nuestras variables con un mapa de calor, asi podremos estudiar cual de nuestros objetivos para probar la hipótesis puede resultar más interesante. Observemos el siguiente mapa de calor

```{r, echo=FALSE}
datos_numericos %>% cor(.) %>% ggcorrplot(hc.order =TRUE, lab = TRUE,
        colors = c("#2F9AA1",
                    "white", "#E14120"), method = 'square') + ggtitle('Mapa de calor. Correlaciones')

```

Como podemos observar hay una alta correlación positiva entre el viento y la altura de las olas. Y la altura tiene una relación positiva con la energía. Sin embargo, como veremos después una disminución del periodo viene relacionado con peores olas, y la matriz de correlaciones nos indica que un aumento del viento puede llevar a una disminución del periodo.

Para realizar los futuros contrastes nos interesa saber si nuestras variables siguen una distribución normal. Para ello hemos realizado un shapiro test en cada variable y no hay nada que nos haga suponer lo contrario. A excepción de la temperatura. Pero como hemos visto en el mapa de calor hay una baja correlación de las variables con la temperatura, y para segun que tratamientos la obviaremos.


# Surf-Rating


El surf-rating se definira como una variable cualitativa de 6 niveles. Esta variable indicará la calidad de la ola para hacer surf siendo 1 muy mala y 6 muy buena. Niveles:

-   *Baja y poca fuerza (BPF)*: Olas de menos de 0.5 metros o de energia menor que 80kJ.
-   *Olas bajas (B)*: Olas de entre 0.6 y 0.9 metros, con una energía mayor de 80 kJ.
-   *Oleaje medio movido (MM)*: Olas de entre 1 y 1.4 metros, con viento a sur, sur-osete o sur-este.
-   *Oleaje medio glass (MG)*: Olas de entre 1 y 1.4 metros, con viento de tierra.
-   *Oleaje alto movido (AM)*: Olas de mas de 1.5 metros, con viento a sur.
-   *Oleaje alto glass (AG)*: Olas de mas de 1.5 metros, con viento de tierra.

```{r}
datos <- datos %>% mutate(SurfR = case_when(
    (A <= 0.5 | En < 80) ~ "BPF",  
    (A >= 0.6 & A < 1) ~ "B",
    (A >= 1 & A <= 1.4 & DV %in% c("S", "SW", "SE", "E")) ~ "MM",
    (A >= 1 & A <= 1.4 & DV %in% c("N", "NW", "NE", "W")) ~ "MG", 
    (A > 1.4 & DV %in% c("S", "SW", "SE", "E")) ~ "AM",  
    (A > 1.4 & DV %in% c("N", "NW", "NE","W")) ~ "AG",
    TRUE ~ NA_character_  # Para cualquier otro caso (opcional), asignar NA
  ))
```

Esta variable sera muy interesante para el surfista. 

También añadiremos una condición de la ola en función del periodo clasificandolas en 4 estrellas.

-   *1 Estrella* : La ola es BPF,B o es MM con un periodo menor que 8.5
-   *2 Estrellas*: La ola es MM con periodo mayor que 8.5 o MG con un periodo hasta 10
-   *3 Estrellas*: La ola es MG con periodo mayor que 10 o AM, o AG con periodo hasta 10
-   *4 Estrellas*: La ola es AG con un periodo mayor que 10

```{r}
datos <- datos %>% mutate(Stars = case_when(
    (SurfR %in% c('BPF','B')) ~ 1,
    (SurfR == 'MM' & P < 8.5) ~ 1,
    (SurfR == 'MM' & P >= 8.5 ) ~ 2,
    (SurfR == 'MG' & P < 10) ~ 2,
    (SurfR == 'MG' & P >= 10) ~ 3,
    (SurfR == 'AG' & P < 10) ~ 3,
    (SurfR %in% c('AM')) ~ 3,
    (SurfR == 'AG' & P >= 10 ) ~ 4,
    TRUE ~ 0# Para cualquier otro caso (opcional), asignar NA
  ))
```


Ahora supongamos que un surfista se va un puente a Bilbao y le gustaria saber si tendra buenas olas. Para ello modelizamos con una multinomial $X = (X_1,X_2,X_3,X_4) $ donde $X_i$ es el número de dias que ha habido con una calidad de olas $i$. Entonces $X \sim Multinom(n,p_1,p_2,p_3,p_4)$ donde las $p_i$ son las siguientes probabilidades. 

```{r, echo=FALSE} 
# Limpieza de datos y cálculo de probabilidades
multiN_data <- datos$Stars
n <- length(multiN_data)
probabilidades <- table(multiN_data)/n
probabilidades
```
Para el surfista de nivel medio que va a estar un puente en Bilbao le interesa saber que cual es la probabilidad de que en 4 dias haya al menos un dia de olas de calidad 3 $P(MG \geq 1)$.

Si tenemos un $Multinom(4,p_{AG},p_{AM},p_{BPF},p_{MG},p_{MM})$ entonces:

$$
P(MG \geq 1) = 1 - P(MG = 0)
$$
```{r, echo=FALSE}
p = probabilidades[3]
P = 1 - (1-p)^(4)
print(paste('Probabilidad de que un dia haya olas medias con viento de tierra: ',
            as.character(round(P,3))))
```

Sin embargo a un surfista profesional le gustaria saber cuando debe comprarse el billete de vuelta para tener al menos un dia de calidad 4 con una probabilidad del 0.9.

# Descripción por regresión lineal

Supongamoos ahora que nuestra boya mide el periodo, la altura y tenemos un medidor de la velocidad del viento. Entonces intentaremos diseñar un modelo de regresión lineal para aproximar cual seria la energía. 

Lo hacemos de esta manera porque muchas veces es complicado medir la energía que tiene una ola, sin embargo si disponemos de una bolla y un () podremos saber cuales son los datos. La energía de la ola es un dato importante para el surfista porque así sabra si el tipo de ola es el adequado para la tabla que utiliza y su experiencia.

En el análisis exploratorio de nuestras variables hemos visto que podíamos suponer normalidad en la energía pero no era así para la temperatura. Entonces para poder suponer que nuestro modelo lineal sigue una normal, y visto la baja correlación de estas dos variables no tendremos en cuenta la temperatura. Entonces si $X_1,X_2$ y $X_3$ son los datos viento, la altura y el periodo respectivamente deseamos crear un modelo de la forma:

$$ Y = \beta_0 + \beta_1X_1+\beta_2X_2 + \beta_3X_3 + \epsilon$$
Y estimar los parámetros $\beta = (\beta_0,\beta_1,\beta_2,\beta_3)$. En este análisis $\epsilon$ es el termino de error y sigue una multinormal centrada en el cero y homocedática. Entonces $Y\sim \mathcal{N}(X\beta,\sigma^2I)$ donde $X = (\underline{1},X_1,X_2,X_3)$. Si calculamos la función de densidad en función de los parámetros obenemos la siguiente formula:


$$
f_{\beta, \sigma^2}(Y) = \frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}exp\left\{-\frac{1}{\sigma^2}(Y-X\beta)^T(Y-X\beta) \right\}
$$

Sin embargo lo que varia son los parámetros, y además lo único que nos interesa es maximizarla. Entonces como la función logaritmo  es creciente definimos la función información como:

$$
l_Y(\beta,\sigma^2) = log(f_{\beta,\sigma^2}(Y))
$$

Finalmente estudiaremos la variación de esta función con la función Score que la definimos como la parcial de $\beta$. Esta función es un indicador de la variabilidad de la verosimilitud de unos parámetros. Entonces valores proximos al cero nos indican proximidad al máximo de la función de información $l_Y$. La función Score es:

$$
Score(\beta) := \frac{\partial l_Y}{\partial\beta}(\beta,\sigma^2) = \frac{1}{\sigma^2}X^T(Y-X\beta) 
$$
```{r,echo=FALSE}
X <- datos_numericos %>% dplyr::select(V,P,A) %>% mutate(V1 = 1)
X <- X[,c('V1','V','P','A')] %>% as.matrix()
Y <- datos_numericos %>% dplyr::select(En) %>% as.matrix()
Score <- function(b){
  return(t(X)%*%(Y-X%*%b))
}
```

Entonces con la función lm de R podemos calcular los coeficientes con la fórmula $(X^tX)^{-1}(X^tY)$ y verificar con la función Score 


```{r}
b = solve(t(X)%*%X)%*%(t(X)%*%Y) 

recta_r <- function(x1,x2,x3){
  n = length(x1)
  v = matrix(c(rep(1,n),x1,x2,x3), ncol = 4, byrow = FALSE)
  return(v%*%b)
}

t(Score(b))
```

Y como podemos observar la función de R nos define valores muy próximos a lo deseado. Observemos caunto nos desajustamos en las predicciones duranto los 100 dias

```{r,echo=FALSE}
graf1 <- datos %>% dplyr::select(DAT,En)
graf2 <- datos %>% mutate(En2 = recta_r(datos$V,datos$P,datos$A)) %>% dplyr::select(DAT,En2)

ggplot() +
  geom_line(data = graf1, aes(x = DAT, y = En, color = "Y1", group = 1), size = 0.8) +
  geom_line(data = graf2, aes(x = DAT, y = En2, color = "Y2", group = 1), size = 0.5) +
  labs(title = "Valores reales frente la aproximación",
       x = "Días",
       y = "Energía de las olas") +
  scale_color_manual(name = "Variables", values = c("Y1" = "blue", "Y2" = "red")) +
  theme_minimal()+theme(axis.text.x = element_blank())


```


# Contraste de la hipótesis

```{r,echo=FALSE}
Y_mar <- datos %>% filter(DV%in%c('N','NW','NE'))%>% dplyr::select(V,En,P,A) 

Y_tierra <- datos %>% filter(DV %in% c('S','SW','SE'))%>% dplyr::select(V,En,P,A) 
```

###   Afecta la dirección del viento a las características de la ola?

Definiremos dos 'poblaciones' en función de la dirección del viento y realizamos un test del tipo:

$$
H_0: \mathbb{\mu_1} = \mu_2 
$$
Pero siguen nuestras distribuciones una multinomial? Si realizamos un test de normalidad de cada una de las variables observamos que si, exceptuando la temperatura que no la tendremos en cuenta por la baja correlación (Test de independencia?). Haremos un hotelling test nosotros y lo compararemos con la función de R.

Sabemos la relación de la F de fisher-Snedecor con la T-Hotteling es:

$$
F^p_{m+p-1} = \frac{m+p-1}{mp}T^2(p,m)    
$$

Entonces lo utilizaremos para calcular el p-valor con la función pf de R. Después comparamos nuestro resultado con la función test.hotelling() del paquete Hotelling.

```{r}
# La siguiente función dado un valor de una T de Hotelling junto
# sus grados de libertad nos calcula la probabilidad de un valor menor  o igual


test_H <- function(Y1,Y2){
  mu1 = colMeans(Y1) %>% as.matrix()
  n1 = length(col(Y1[1]))
  S1 = cov(Y1)
  
  mu2 = colMeans(Y2) %>% as.matrix()
  n2 = length(col(Y2[1]))
  S2 = cov(Y2)
  
  p = length(Y1)
  if (p != length(Y2)){
    return(print('WARNING: No hay el mismo número de variables'))
  }
  
  s = (n1+n2 -1 -p)*n1*n2/((n1+n2-2)*p*(n1+n2))
  S = (n1*S1+n2*S2)/(n1+n2-2)
  S_inv = solve(S)
  
  H = tibble(Valor_estadistico = 0,
             df_num= p,
             df_den = n1+n2-1-p,
             pvalor= 0)
  t =  s*t((mu2-mu1))%*%S_inv%*%(mu2-mu1)
  H$Valor_estadistico =t*((n1+n2-2)*p)/(n1+n2-p -1)
  
  H$pvalor= 1-pf(t,p,n1+n2-p-1)
  
  return(H)
  
}
```

```{r, echo=FALSE}
print(test_H(Y_mar,Y_tierra))
```
Unos valores muy parecidos a la función de R que son los siguientes:

```{r,echo = FALSE}
print(hotelling.test(Y_mar,Y_tierra))
```






###   La calidad de la ola esta relacionada con una variación de la energía?


Para este contraste nos volvemos a definir dos subpoblaciones en función de si tienen dos estrellas o menos y si tienen 3 o más. Y hacemos un test de hotelling como el definido anteriormente. Y obtenemos los siguientes resultados:

```{r}
En12 <- datos %>% filter(Stars <= 2) %>% dplyr::select(En)
En34 <- datos %>% filter(Stars >= 3) %>% dplyr::select(En)

valor <- c(En12$En, En34$En)
nivel <- c(rep('Calidad 1 y 2', length(En12$En)),rep('Calidad 3 y 4',length(En34$En)))

graf_stars <- tibble(Calidad = nivel,
                     Energia = valor)
ggplot(graf_stars, aes(x = Calidad, y = Energia, fill = Calidad)) + geom_violin() +
  labs(title = 'Energías segun las calidades') + theme_minimal()

```


```{r}


print(test_H(En12,En34))
```
Este p-valor, indica una probabilidad muy baja de haber observado el valor del estadiístico suponiendo que las medias de las energías son iguales. Al ser el P-valor tan cercano a cero no sería muy verosímil nuestra hipótesis. Entonces la energía en las olas de mayor calidad esta desplazada (en concreto es mayor)



# Conclusión

Como hemos observado la energía es un factor importante para la calidad de la ola, y una mayor calidad de esta relacionado con una mayor energía. El  modelo de regresión para preveer la energía aunque hay errores que distan hasta 30kJ, aunque teniendo en cuenta la variabilidad de esta variable no son errores tran grandes. La magnitud de estos errores también pueden venir relacionadas con la dependencia temporal que hemos creado en la base de datos, ya que el modelo de regresión no tiene en cuenta los valores de los días anteriores. Tener en cuenta que variables como la altura o la energía no pueden ser independientes al tiempo ya que hay un 'tiempo de recuperación'. No es como quien tira un dado.

Hay que tener en cuenta que hemos creado nuestra propia base de datos (veáse como en el anexo), que para modelar datos metereológicos debemos ir con precaución ya que no se expresan los picos que se observan en la naturaleza como las rachas de viento. Es más recomendable crear un modelo númerico mezclando modelos físicos que describan el comportamiento y la estadística. Por ejemplo el Puerto de Estado tiene un conjunto de datos SIMAR creados a partir de modelos numéricos mucho más precisos. Aun así suelen trabajar con el mismo problema de los picos.




# Anexo
## Construcción de la base de datos

```{r, echo=TRUE, message=FALSE}
covarianza <- matrix(c(13, 77, -2, 0.25,
                       77, 5000, 134, 10,
                       -2, 134, 6, 0.12,
                       0.25, 10, 0.12, 0.05), ncol = 4, byrow = TRUE)

medias <- c(8, 164, 10, 1.3)

set.seed(43)
datos_numericos <- mvrnorm(200, mu = medias, covarianza) %>% as.tibble()
names(datos_numericos) <- c('V','En','P','A')

# Limitamos a resultados realistas

datos_numericos <- datos_numericos %>%
  mutate(
    V = pmax(V, 0),    
    En = pmin(pmax(En, 1), 5000),  # Energía entre 1 y 5000
    P = pmin(pmax(P, 5), 20),      # Periodo entre 5 y 20 s
    A = pmin(pmax(A, 0), 20)      # Altura entre 0 y 20 m
  )
# Suponemos que nuestra bolla mide cada 12 horas
direccion_viento <- sample(c('N','W','S','E',
                             'NW','NE','SW','SE'),200, replace = TRUE)
marea <- rep(c("ALTA", "BAJA"), times = 100)

primer_dia <- as.Date("2017-01-01") 
fechas <- seq(from = primer_dia, by ='day', length.out = 100) 
DAT = c()
for (i in 1:100){
  DAT = c(DAT, paste(as.character(fechas[i]), 'mañana'),paste(as.character(fechas[i]), 'tarde'))
}
datos_cual <- tibble(DV = direccion_viento,
                    M  = marea,
                    DAT = DAT)

# Añadimos una dependencia temporal
for (i in 2:200) {
  datos_numericos$A[i] <- 0.3 * datos_numericos$A[i - 1] + 
    0.5 * datos_numericos$A[i] + (datos_numericos$V[i]/8*1.3)*0.2 
  
  datos_numericos$En[i] <- 0.3 * datos_numericos$En[i - 1] + 
    0.7 * datos_numericos$En[i]
}



datos <- tibble(datos_numericos,datos_cual)

kaggle_data <- read.csv('kaggle_data.csv',header = TRUE) 
datos_nuevos <- kaggle_data  %>%  
  filter(grepl('8:00',Date.Time) | grepl('20:00',Date.Time)) %>%
  dplyr::select(Date.Time,SST) %>% slice(1:200)


fechas <- seq(from = primer_dia, by ='day', length.out = 100) 
DATK = c()
for (i in 1:100){
  DATK = c(DATK, paste(as.character(fechas[i]), 'mañana'),paste(as.character(fechas[i]), 'tarde'))
}

datos_nuevos <- datos_nuevos %>% mutate(
  Date.Time = DATK) 
names(datos_nuevos) <- c('DAT','SST')

datos <- datos %>% right_join(datos_nuevos) 
```
# Referencias
